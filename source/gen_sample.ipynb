{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffdf8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "import soundfile as sf\n",
    "import random\n",
    "import re\n",
    "import IPython.display as ipd\n",
    "from IPython.display import display, HTML\n",
    "from datasets import load_dataset, load_metric, ClassLabel\n",
    "import json\n",
    "\n",
    "from constants import SAMPLE_RATE\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n",
    "\n",
    "file_phoneme_dict = \"../model/phoneme_dict.json\"\n",
    "file_index = \"../data/timit/index.txt\"\n",
    "\n",
    "timit = load_dataset(\"timit_asr\")\n",
    "timit = timit.remove_columns([\n",
    "    #\"phonetic_detail\", \n",
    "    \"word_detail\", \n",
    "    \"dialect_region\", \n",
    "    \"id\", \n",
    "    \"sentence_type\", \n",
    "    \"speaker_id\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b519baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "show_random_elements(timit[\"train\"].remove_columns([\"file\"]), num_examples=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(batch):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    batch[\"text\"] = re.sub(chars_to_ignore_regex, \"\", batch[\"text\"]).lower()\n",
    "    \n",
    "    return batch\n",
    "\n",
    "\n",
    "timit = timit.map(remove_special_characters)\n",
    "show_random_elements(timit[\"train\"].remove_columns([\"file\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_phn(batch):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    batch[\"target_phoneme\"] = batch[\"phonetic_detail\"][\"utterance\"]\n",
    "    # batch[\"target_phoneme\"] = list(map(lambda x: dict_phoneme[x], batch[\"phonetic_detail\"][\"utterance\"]))\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "# with open(file_phoneme_dict, \"r\") as f_phoneme_dict:\n",
    "#     dict_phoneme = json.load(f_phoneme_dict)\n",
    "\n",
    "timit = timit.map(get_target_phn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5128933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(batch):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    speech_array, sampling_rate = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"sampling_rate\"] = sampling_rate\n",
    "    batch[\"target_text\"] = batch[\"text\"]\n",
    "    batch[\"phoneme\"] = batch[\"phonetic_detail\"][\"utterance\"]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "\n",
    "timit = timit.map(speech_file_to_array_fn, remove_columns=timit.column_names[\"train\"], num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4231190",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_int = random.randint(0, len(timit[\"train\"]))\n",
    "ipd.Audio(data=np.asarray(timit[\"train\"][rand_int][\"speech\"]), autoplay=True, rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f4db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_int = random.randint(0, len(timit[\"train\"]))\n",
    "\n",
    "print(\"Target text:\", timit[\"train\"][rand_int][\"target_text\"])\n",
    "print(\"Input array shape:\", np.asarray(timit[\"train\"][rand_int][\"speech\"]).shape)\n",
    "print(\"Sampling rate:\", timit[\"train\"][rand_int][\"sampling_rate\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aec4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d330a9",
   "metadata": {},
   "source": [
    "# Generate representations for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "    path_sample = os.path.join(\"../data/timit\", split)\n",
    "    \n",
    "    num_sample = len(timit[split])\n",
    "    print(\"number of samples in {} set: {}\".format(split, num_sample))\n",
    "    \n",
    "    for i in range(num_sample):\n",
    "        input_values = processor(timit[split][i][\"speech\"], \n",
    "                                 sampling_rate=timit[split][i][\"sampling_rate\"], \n",
    "                                 return_tensors=\"pt\").input_values.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            last_hidden_state = model(input_values).last_hidden_state.detach().numpy()\n",
    "            last_hidden_state = last_hidden_state.reshape([last_hidden_state.shape[-2], last_hidden_state.shape[-1]])\n",
    "            \n",
    "            file_sample = os.path.join(path_sample, \"{}.npy\".format(str(i).zfill(4)))\n",
    "            np.save(file_sample, last_hidden_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_phn_train = []\n",
    "num_sample = len(timit[\"train\"])\n",
    "print(\"number of samples in {} set: {}\".format(\"train\", num_sample))\n",
    "for i in range(num_sample):\n",
    "    list_phn_train.append(timit[\"train\"][i][\"phoneme\"])\n",
    "\n",
    "list_phn_test = []\n",
    "num_sample = len(timit[\"test\"])\n",
    "print(\"number of samples in {} set: {}\".format(\"test\", num_sample))\n",
    "for i in range(num_sample):\n",
    "    list_phn_test.append(timit[\"test\"][i][\"phoneme\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d8379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index_train = pd.DataFrame({\n",
    "    \"split\": \"train\",\n",
    "    \"sample_index\": [i for i in range(len(timit[\"train\"][\"target_text\"]))],\n",
    "    \"target_text\": timit[\"train\"][\"target_text\"],\n",
    "    \"target_phoneme\": list_phn_train\n",
    "})\n",
    "\n",
    "df_index_test = pd.DataFrame({\n",
    "    \"split\": \"test\",\n",
    "    \"sample_index\": [i for i in range(len(timit[\"test\"][\"target_text\"]))],\n",
    "    \"target_text\": timit[\"test\"][\"target_text\"],\n",
    "    \"target_phoneme\": list_phn_test\n",
    "})\n",
    "\n",
    "df_index = pd.concat([df_index_train, df_index_test]).reset_index(drop=True)\n",
    "df_index.to_csv(file_index, sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b396b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_phoneme = [\n",
    "    'aa',\n",
    "    'ae',\n",
    "    'ah',\n",
    "    'ao',\n",
    "    'aw',\n",
    "    'ax',\n",
    "    'ax-h',\n",
    "    'axr',\n",
    "    'ay',\n",
    "    'b',\n",
    "    'bcl',\n",
    "    'ch',\n",
    "    'd',\n",
    "    'dcl',\n",
    "    'dh',\n",
    "    'dx',\n",
    "    'eh',\n",
    "    'el',\n",
    "    'em',\n",
    "    'en',\n",
    "    'eng',\n",
    "    'epi',\n",
    "    'er',\n",
    "    'ey',\n",
    "    'f',\n",
    "    'g',\n",
    "    'gcl',\n",
    "    'h#',\n",
    "    'hh',\n",
    "    'hv',\n",
    "    'ih',\n",
    "    'ix',\n",
    "    'iy',\n",
    "    'jh',\n",
    "    'k',\n",
    "    'kcl',\n",
    "    'l',\n",
    "    'm',\n",
    "    'n',\n",
    "    'ng',\n",
    "    'nx',\n",
    "    'ow',\n",
    "    'oy',\n",
    "    'p',\n",
    "    'pau',\n",
    "    'pcl',\n",
    "    'q',\n",
    "    'r',\n",
    "    's',\n",
    "    'sh',\n",
    "    't',\n",
    "    'tcl',\n",
    "    'th',\n",
    "    'uh',\n",
    "    'uw',\n",
    "    'ux',\n",
    "    'v',\n",
    "    'w',\n",
    "    'y',\n",
    "    'z',\n",
    "    'zh'\n",
    "]\n",
    "dict_phoneme = dict(zip(list_phoneme, [i for i in range(len(list_phoneme))]))\n",
    "\n",
    "# dict_phoneme[\"[UNK]\"] = len(dict_phoneme)\n",
    "dict_phoneme[\"[PAD]\"] = len(dict_phoneme)\n",
    "\n",
    "file_phoneme_dict = \"../model/phoneme_dict.json\"\n",
    "with open(file_phoneme_dict, \"w\") as f_phoneme_dict:\n",
    "    json.dump(dict_phoneme, f_phoneme_dict, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8a9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
